"""
PTO Code Generator for Ascend A2/A3 Cycle-Accurate Simulator

This module generates code for cycle-accurate simulation of Ascend A2/A3 NPU.

Key Features:
- Generates actual Ascend instructions for InCore functions (same as ascend_a2a3)
- Generates orchestration code with task submission for runtime scheduling
- Uses A2A3 Core Simulator for cycle-accurate execution timing
- Supports dual-queue scheduling (vector/cube)
- Generates trace output for waveform analysis

Architecture Model:
- Vector Core: handles element-wise ops, reductions, memory ops
- Cube Core: handles matrix multiply operations
- Memory Hierarchy: GM (global) -> L1/UB (scratchpad) -> Register

The simulation uses the same InCore function code as physical Ascend A2/A3,
but executes them through the core simulator for cycle-accurate timing.
"""

import os
import sys
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass

# Add parent directories to path
_current_dir = os.path.dirname(os.path.abspath(__file__))
_src_dir = os.path.dirname(_current_dir)
if _src_dir not in sys.path:
    sys.path.insert(0, _src_dir)

from compile.pto_compile_common import (
    PTOProgram, PTOModule,
    MockInstruction, MockTileInfo, convert_program_to_mock_instructions,
    TileBufferAnalyzer,
)
from isa_definition.pto_isa_definition import (
    ElementType, MemorySpace,
    ARM64_TYPE_MAP,  # Reuse for C types
    ASCEND_TYPE_MAP,
    ascend_generate_header,
)

# Import AscendCodeGenerator for InCore function generation
from compile.pto_codegen_ascend import (
    AscendCodeGenerator,
    gen_ascend_barrier_op,
    gen_ascend_single_op,
    AscendFusedCodeGenerator,
)

# =============================================================================
# Cycle Cost Model for Ascend A2/A3
# =============================================================================

# Cycle costs for different operations (approximate for 910B @ 1.8GHz)
ASCEND_A2A3_CYCLE_COSTS = {
    # Memory operations (GM access is expensive)
    "TLOAD": 100,
    "TSTORE": 100,
    
    # Element-wise operations (Vector Engine)
    "TADD": 8,
    "TSUB": 8,
    "TMUL": 8,
    "TDIV": 16,
    "TEXP": 24,
    "TLOG": 24,
    "TSQRT": 16,
    "TRSQRT": 16,
    "TSILU": 20,
    "TRELU": 8,
    "TTANH": 24,
    "TSIGMOID": 24,
    "TGELU": 28,
    "TABS": 4,
    "TNEG": 4,
    
    # Scalar-tile operations
    "TADDS": 8,
    "TSUBS": 8,
    "TMULS": 8,
    "TDIVS": 16,
    "TMAXS": 8,
    "TMINS": 8,
    
    # Reduction operations
    "TROWSUM": 20,
    "TROWMAX": 20,
    "TROWMIN": 20,
    "TCOLSUM": 20,
    "TCOLMAX": 20,
    "TCOLMIN": 20,
    
    # Broadcast operations
    "TROWEXPAND": 12,
    "TCOLEXPAND": 12,
    "TROWEXPANDADD": 16,
    "TROWEXPANDSUB": 16,
    "TROWEXPANDMUL": 16,
    "TROWEXPANDDIV": 20,
    
    # Matrix operations (Cube Engine)
    "TMATMUL": 50,      # Per 32x32 output tile
    "TMATMULACC": 50,
    
    # Comparison
    "TCMP": 8,
    "TCMPS": 8,
    "TSEL": 10,
    "TSELS": 10,
    
    # Data movement
    "TMOV": 4,
    "TCVT": 8,
    "TTRANS": 16,
    
    # Control flow (negligible)
    "FOR": 1,
    "ENDFOR": 1,
    "IF": 1,
    "ELSE": 1,
    "ENDIF": 1,
    "CALL": 2,
    "RETURN": 1,
    
    # Scalar operations
    "SLI": 1,
    "SADD": 1,
    "SSUB": 1,
    "SMUL": 1,
    "SDIV": 2,
    "SCMP": 1,
}

# Which operations go to Cube Engine vs Vector Engine
CUBE_OPS = {"TMATMUL", "TMATMULACC"}
VECTOR_OPS = set(ASCEND_A2A3_CYCLE_COSTS.keys()) - CUBE_OPS - {"FOR", "ENDFOR", "IF", "ELSE", "ENDIF", "CALL", "RETURN"}


def get_cycle_cost(opcode: str, rows: int = 32, cols: int = 128) -> int:
    """
    Get cycle cost for an operation.
    
    Scales based on tile size relative to base 32x128.
    """
    base_cost = ASCEND_A2A3_CYCLE_COSTS.get(opcode, 10)
    
    # Scale by tile size
    base_elements = 32 * 128
    actual_elements = rows * cols
    scale = max(1, actual_elements // base_elements)
    
    return base_cost * scale


def is_cube_op(opcode: str) -> bool:
    """Check if operation uses Cube Engine."""
    return opcode in CUBE_OPS


# =============================================================================
# Header Generation (Simulator and Hardware)
# =============================================================================

def generate_sim_header(target_mode: str = "sim") -> str:
    """Generate header for code.
    
    Args:
        target_mode: "sim" for simulator, "hardware" for real A2A3 hardware
    """
    if target_mode == "hardware":
        return '''// PTO Ascend A2/A3 Runtime
// Auto-generated by PTO ISA Compiler
// 
// This code runs on real Ascend A2/A3 hardware using CANN SDK.
// InCore functions contain actual Ascend instructions.

#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <stdbool.h>
#include <string.h>
#include <math.h>

// Enable A2A3 platform for dual-queue execution
#define PTO_PLATFORM_A2A3
#define A2A3_TARGET_HARDWARE

// Include PTO runtime for A2A3 hardware
#include "pto_runtime.h"
#include "pto_runtime.c"

// Include A2A3 hardware runtime (uses CANN SDK)
#include "runtime_a2a3/core/a2a3_incore.h"

'''
    else:
        return '''// PTO Ascend A2/A3 Cycle-Accurate Simulator
// Auto-generated by PTO ISA Compiler
// 
// This code uses the A2A3 Core Simulator for cycle-accurate InCore execution.
// InCore functions contain actual Ascend instructions that are parsed and
// simulated by the core model.

#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <stdbool.h>
#include <string.h>
#include <math.h>

// Enable A2A3 platform for dual-queue simulation
#define PTO_PLATFORM_A2A3
#define A2A3_TARGET_SIMULATOR

// Include PTO runtime with simulation support
#include "pto_runtime.h"
#include "pto_runtime.c"

// Include A2A3 Core Simulator (for cycle-accurate simulation)
// Note: The core simulator is linked separately as liba2a3_core.a
// If not available, we fall back to heuristic cycle estimation

#ifdef A2A3_CORE_SIM_AVAILABLE
#include "runtime_a2a3_sim/core_model/a2a3_core_model.h"
#include "runtime_a2a3_sim/core_model/a2a3_incore_sim.h"
#endif

'''


def generate_incore_function_registry() -> str:
    """Generate code for registering InCore functions with the core simulator."""
    return '''
// =============================================================================
// InCore Function Registry (for Core Simulator)
// =============================================================================

#ifdef A2A3_CORE_SIM_AVAILABLE
static IncoreSimulator* g_incore_sim = NULL;

void init_incore_simulator(void) {
    if (!g_incore_sim) {
        g_incore_sim = a2a3_incore_sim_create();
    }
}

void cleanup_incore_simulator(void) {
    if (g_incore_sim) {
        a2a3_incore_sim_destroy(g_incore_sim);
        g_incore_sim = NULL;
    }
}

// Get cycle cost using core simulator
int64_t get_incore_cycle_cost_sim(const char* func_name, int64_t tile_size) {
    if (g_incore_sim) {
        return a2a3_incore_sim_execute_by_name(g_incore_sim, func_name);
    }
    return a2a3_get_incore_cycle_cost(func_name, tile_size);
}
#else
// Fallback when core simulator not available
void init_incore_simulator(void) {}
void cleanup_incore_simulator(void) {}

int64_t get_incore_cycle_cost_sim(const char* func_name, int64_t tile_size) {
    // Heuristic estimation based on function name
    if (strstr(func_name, "matmul") || strstr(func_name, "gemm")) return 50;
    if (strstr(func_name, "rmsnorm") || strstr(func_name, "layernorm")) return 70;
    if (strstr(func_name, "softmax")) return 70;
    if (strstr(func_name, "rope")) return 60;
    if (strstr(func_name, "swiglu") || strstr(func_name, "silu")) return 25;
    if (strstr(func_name, "attention") || strstr(func_name, "score")) return 60;
    if (strstr(func_name, "rowsum") || strstr(func_name, "rowmax")) return 20;
    if (strstr(func_name, "add") || strstr(func_name, "mul")) return 10;
    if (strstr(func_name, "exp") || strstr(func_name, "sqrt")) return 10;
    return 10;  // Default
}
#endif

'''


def generate_sim_main(orch_func_name: str, params: List[Tuple[str, str]]) -> str:
    """Generate main function for simulation."""
    # Build parameter declarations for test data
    param_decls = []
    param_array_setup = []
    free_stmts = []
    
    # Track parameters and their indices
    for i, (ptype, pname) in enumerate(params):
        if '*' in ptype:
            # Pointer - allocate test data
            base_type = ptype.replace('*', '').strip()
            param_decls.append(f"    {base_type}* {pname} = ({base_type}*)calloc(1024 * 1024, sizeof({base_type}));")
            param_array_setup.append(f"    user_data[{i}] = (void*){pname};")
            free_stmts.append(f"    free({pname});")
        else:
            # Scalar - use default value or command line argument
            if 'int' in ptype:
                param_decls.append(f"    {ptype} {pname} = 16;  // Default")
            else:
                param_decls.append(f"    {ptype} {pname} = 1.0f;  // Default")
            param_array_setup.append(f"    user_data[{i}] = (void*)&{pname};")
    
    num_params = len(params)
    
    return f'''
// =============================================================================
// Main Function for Cycle-Accurate Simulation
// =============================================================================
// Usage: {orch_func_name} [--benchmark-only] [seq_len] [tile_rows] [num_tiles] [zero]
// Flags:
//   --benchmark-only  - Only run orchestration (skip simulation), output stats
// Environment variables:
//   PTO_TRACE_OUTPUT=file - Output trace file path

int main(int argc, char** argv) {{
    // Check for --benchmark-only flag
    int benchmark_only = 0;
    int arg_offset = 0;
    
    for (int i = 1; i < argc; i++) {{
        if (strcmp(argv[i], "--benchmark-only") == 0) {{
            benchmark_only = 1;
            arg_offset = 1;
            break;
        }}
    }}
    
    if (!benchmark_only) {{
        printf("=== Ascend A2/A3 Cycle-Accurate Simulator ===\\n");
        printf("    Platform: Ascend 910B (A2/A3)\\n");
        printf("    Workers:  %d vector + %d cube\\n", 
               A2A3_DEFAULT_VECTOR_WORKERS, A2A3_DEFAULT_CUBE_WORKERS);
#ifdef A2A3_CORE_SIM_AVAILABLE
        printf("    Core Sim: Enabled (cycle-accurate)\\n\\n");
#else
        printf("    Core Sim: Disabled (using heuristics)\\n\\n");
#endif
    }}
    
    // Initialize InCore simulator
    init_incore_simulator();
    
    // Initialize runtime (heap allocated due to large size)
    PTORuntime* rt = (PTORuntime*)calloc(1, sizeof(PTORuntime));
    if (!rt) {{
        fprintf(stderr, "Failed to allocate runtime\\n");
        return 1;
    }}
    pto_runtime_init(rt);
    
    // Enable A2A3 simulation with platform-defined worker configuration
    // A2A3 (Ascend 910B): 48 vector workers + 24 cube workers
    pto_runtime_enable_a2a3_sim(rt, A2A3_DEFAULT_VECTOR_WORKERS, A2A3_DEFAULT_CUBE_WORKERS);
    
    // Allocate test data
{chr(10).join(param_decls)}

    // Parse command line arguments for integer parameters (with offset for --benchmark-only flag)
    if (argc > 1 + arg_offset) seq_len = atoi(argv[1 + arg_offset]);
    if (argc > 2 + arg_offset) tile_rows = atoi(argv[2 + arg_offset]);
    if (argc > 3 + arg_offset) num_tiles = atoi(argv[3 + arg_offset]);
    if (argc > 4 + arg_offset) zero = atoi(argv[4 + arg_offset]);

    // Set up parameter array (void** for orchestration function)
    void* user_data[{num_params}];
{chr(10).join(param_array_setup)}

    // Print configuration
    if (!benchmark_only) {{
        printf("Configuration:\\n");
        printf("  num_tiles = %d\\n", num_tiles);
        printf("\\nPhase 1: Building task graph...\\n");
    }}
    
    // === BENCHMARK: Measure orchestration time ===
    struct timespec start_time, end_time;
    clock_gettime(CLOCK_MONOTONIC, &start_time);
    
    // Call orchestration function to build task graph (using void** interface)
    {orch_func_name}(rt, (void*)user_data);
    
    clock_gettime(CLOCK_MONOTONIC, &end_time);
    double orch_time_ms = (end_time.tv_sec - start_time.tv_sec) * 1000.0 +
                          (end_time.tv_nsec - start_time.tv_nsec) / 1000000.0;
    // === END BENCHMARK ===
    
    int64_t tasks_submitted = rt->total_tasks_scheduled;
    
    if (benchmark_only) {{
        // Benchmark mode: just output stats in parseable format
        double tasks_per_ms = tasks_submitted / orch_time_ms;
        printf("BENCHMARK: num_tiles=%d tasks=%lld time_ms=%.3f tasks_per_ms=%.2f\\n",
               num_tiles, (long long)tasks_submitted, orch_time_ms, tasks_per_ms);
    }} else {{
        printf("  Submitted %lld tasks\\n", (long long)tasks_submitted);
        printf("  Orchestration time: %.3f ms (%.2f tasks/ms)\\n", 
               orch_time_ms, tasks_submitted / orch_time_ms);
        
        // Dump task graph before simulation
#ifdef PTO_TASK_DUMP
        pto_runtime_dump(rt, "{orch_func_name}_task_graph.txt");
#endif
        
        printf("\\nPhase 2: Running cycle-accurate simulation...\\n");
        
        // Run cycle-accurate simulation
        pto_simulate_all(rt);
        
        // Print cycle trace summary
        pto_trace_print_summary();
        
        // Save trace to JSON for visualization
        const char* trace_file = getenv("PTO_TRACE_OUTPUT");
        if (!trace_file) {{
            trace_file = "trace.json";
        }}
        pto_trace_write_json(trace_file);
        printf("Trace saved to: %s\\n", trace_file);
        printf("  Open in Chrome: chrome://tracing and load the file\\n");
    }}
    
    // Shutdown and free resources
    pto_runtime_shutdown(rt);
    free(rt);
    cleanup_incore_simulator();
    
    // Free test data
{chr(10).join(free_stmts)}
    
    if (!benchmark_only) {{
        printf("\\n=== Simulation Complete ===\\n");
    }}
    return 0;
}}
'''


# =============================================================================
# InCore Function Code Generator (generates PTO ISA API calls)
# =============================================================================

# PTO ISA instruction mapping
PTO_ISA_OPS = {
    # Binary operations
    "TADD": "TADD",
    "TSUB": "TSUB",
    "TMUL": "TMUL",
    "TDIV": "TDIV",
    "TMAX": "TMAX",
    "TMIN": "TMIN",
    
    # Unary operations
    "TABS": "TABS",
    "TNEG": "TNEG",
    "TRECIP": "TRECIP",
    "TEXP": "TEXP",
    "TLOG": "TLOG",
    "TSQRT": "TSQRT",
    "TRSQRT": "TRSQRT",
    "TRELU": "TRELU",
    "TSIGMOID": "TSIGMOID",
    "TTANH": "TTANH",
    "TGELU": "TGELU",
    "TSILU": "TSILU",
    
    # Scalar operations
    "TADDS": "TADDS",
    "TSUBS": "TSUBS",
    "TMULS": "TMULS",
    "TDIVS": "TDIVS",
    "TEXPANDS": "TEXPANDS",
    "TMAXS": "TMAXS",
    "TMINS": "TMINS",
    
    # Row-wise broadcast operations
    "TROWEXPANDSUB": "TROWEXPANDSUB",
    "TROWEXPANDDIV": "TROWEXPANDDIV",
    "TROWEXPANDMUL": "TROWEXPANDMUL",
    "TROWEXPANDADD": "TROWEXPANDADD",
    
    # Reduction operations
    "TROWSUM": "TROWSUM",
    "TROWMAX": "TROWMAX",
    "TROWMIN": "TROWMIN",
    "TCOLSUM": "TCOLSUM",
    "TCOLMAX": "TCOLMAX",
    "TCOLMIN": "TCOLMIN",
    
    # Matrix operations (Cube)
    "TMATMUL": "TMATMUL",
    "TMATMUL_ACC": "TMATMUL_ACC",
    
    # Memory operations
    "TLOAD": "TLOAD",
    "TSTORE": "TSTORE",
    "TCOPY": "TCOPY",
}


class PTOISAIncoreGenerator:
    """
    Generate InCore function code using PTO ISA C++ APIs.
    
    This generates C++ code that uses:
    - pto::Tile<T, M, N> for local tiles in UB memory
    - pto::GlobalTensor<T, Shape, Stride> for global memory tensors
    - PTO ISA instructions: TLOAD, TSTORE, TADD, TMUL, TMATMUL, etc.
    """
    
    def __init__(self, module: Optional[PTOModule] = None):
        self.module = module
    
    def generate(self, program: PTOProgram) -> str:
        """Generate InCore function using PTO ISA APIs."""
        tile_info, mock_instructions = convert_program_to_mock_instructions(program)
        
        lines = []
        
        # Determine if this is a cube or vector function
        is_cube = getattr(program, 'is_cube', False)
        core_type = "Cube" if is_cube else "Vector"
        
        # Generate header
        lines.append(f"// =============================================================================")
        lines.append(f"// PTO ISA InCore Function: {program.name}")
        lines.append(f"// Core Type: {core_type}")
        lines.append(f"// =============================================================================")
        lines.append("")
        
        # Define CCE attributes if not already defined
        # This ensures compatibility with CCE compiler by providing proper [aicore] expansion
        lines.append("#ifndef __gm__")
        lines.append("#define __gm__")
        lines.append("#endif")
        lines.append("")
        lines.append("#ifndef __global__")
        lines.append("#define __global__")
        lines.append("#endif")
        lines.append("")
        lines.append("// For CCE compiler, __aicore__ should expand to [aicore]")
        lines.append("#ifndef __aicore__")
        lines.append("#if defined(__CCE_AICORE__) || defined(__CCE__) || defined(__NPU_ARCH__)")
        lines.append("#define __aicore__ [aicore]")
        lines.append("#else")
        lines.append("#define __aicore__")
        lines.append("#endif")
        lines.append("#endif")
        lines.append("")
        
        # Include PTO headers
        lines.append('#include "pto/common/pto_tile.hpp"')
        lines.append('#include "pto/common/pto_instr.hpp"')
        lines.append("")
        lines.append("using namespace pto;")
        lines.append("")
        
        # Collect tile declarations
        tile_decls = self._generate_tile_declarations(program, tile_info)
        
        # Generate function signature - use AICORE macro for CCE compatibility
        params = self._generate_params(program)
        lines.append(f"AICORE void {program.name}({params}) {{")
        
        # Declare local tiles
        for decl in tile_decls:
            lines.append(f"    {decl}")
        lines.append("")
        
        # Generate GlobalTensor wrappers for memory references
        global_tensors = self._generate_global_tensors(program, tile_info)
        for gt in global_tensors:
            lines.append(f"    {gt}")
        if global_tensors:
            lines.append("")
        
        # Generate PTO ISA instructions
        # Set is_cube flag for instruction generation (used in TLOAD/TSTORE handling)
        self._current_is_cube = is_cube
        for instr in mock_instructions:
            instr_lines = self._generate_instruction(instr, tile_info)
            for line in instr_lines:
                lines.append(f"    {line}")
        
        lines.append("}")
        
        return "\n".join(lines)
    
    def _generate_tile_declarations(self, program: PTOProgram, 
                                     tile_info: Dict[str, MockTileInfo]) -> List[str]:
        """Generate Tile declarations for local buffers.
        
        For cube (matmul) functions, the data flow is:
        1. TLOAD: GM -> Mat tile
        2. TMOV: Mat -> Left/Right tile
        3. TMATMUL: Left + Right -> Acc
        4. TMOV: Acc -> Mat tile
        5. TSTORE: Mat -> GM
        """
        decls = []
        
        # Determine if this is a cube function (matmul uses Left/Right/Acc tiles)
        is_cube = getattr(program, 'is_cube', False)
        
        for name, info in tile_info.items():
            # Skip global memory references
            if name in program.memref_declarations:
                continue
            
            dtype = self._get_cpp_type(info.dtype)
            rows = info.rows
            cols = info.cols
            
            # Determine TileType based on function type and tile usage
            if is_cube:
                # For matmul: A->Left, B->Right, C->Acc
                # Need Mat tiles for TLOAD/TSTORE and Left/Right/Acc for matmul
                name_lower = name.lower()
                if 'a' == name_lower or 'left' in name_lower:
                    # A matrix: Mat tile for loading, Left tile for matmul
                    decls.append(f"Tile<TileType::Mat, {dtype}, {rows}, {cols}> {name}_mat;")
                    decls.append(f"Tile<TileType::Left, {dtype}, {rows}, {cols}> {name};")
                elif 'b' == name_lower or 'right' in name_lower:
                    # B matrix: Mat tile for loading, Right tile for matmul
                    decls.append(f"Tile<TileType::Mat, {dtype}, {rows}, {cols}> {name}_mat;")
                    decls.append(f"Tile<TileType::Right, {dtype}, {rows}, {cols}> {name};")
                elif 'c' == name_lower or 'acc' in name_lower or 'out' in name_lower:
                    # C matrix: Acc tile for matmul, TSTORE directly supports Acc->GM
                    decls.append(f"Tile<TileType::Acc, {dtype}, {rows}, {cols}> {name};")
                else:
                    # Other tiles use Vec
                    decls.append(f"Tile<TileType::Vec, {dtype}, {rows}, {cols}> {name};")
            else:
                # Vector functions use TileType::Vec
                decls.append(f"Tile<TileType::Vec, {dtype}, {rows}, {cols}> {name};")
        
        return decls
    
    def _generate_global_tensors(self, program: PTOProgram,
                                  tile_info: Dict[str, MockTileInfo]) -> List[str]:
        """Generate GlobalTensor wrappers for memory references."""
        tensors = []
        for name, memref_type in program.memref_declarations.items():
            dtype = ARM64_TYPE_MAP.get(memref_type.element_type.value, "float")
            
            # Get shape from tile_info if available, else use default
            if name in tile_info:
                info = tile_info[name]
                rows, cols = info.rows, info.cols
            else:
                rows, cols = 64, 64  # Default
            
            # Create GlobalTensor wrapper
            tensors.append(f"GlobalTensor<{dtype}, Shape<{rows}, {cols}>, "
                          f"Stride<{cols}, 1>> g_{name}({name});")
        
        return tensors
    
    def _generate_params(self, program: PTOProgram) -> str:
        """Generate function parameters."""
        params = []
        
        for name, memref_type in program.memref_declarations.items():
            dtype = ARM64_TYPE_MAP.get(memref_type.element_type.value, "float")
            params.append(f"__gm__ {dtype}* {name}")
        
        for name, scalar_type in program.scalar_declarations.items():
            dtype = ARM64_TYPE_MAP.get(scalar_type.value, "int32_t")
            params.append(f"{dtype} {name}")
        
        return ", ".join(params)
    
    def _generate_wrapper_args(self, program: PTOProgram) -> str:
        """Generate arguments for C wrapper function."""
        args = []
        idx = 0
        
        for name, memref_type in program.memref_declarations.items():
            dtype = ARM64_TYPE_MAP.get(memref_type.element_type.value, "float")
            args.append(f"({dtype}*)args[{idx}]")
            idx += 1
        
        for name, scalar_type in program.scalar_declarations.items():
            dtype = ARM64_TYPE_MAP.get(scalar_type.value, "int32_t")
            args.append(f"*({dtype}*)args[{idx}]")
            idx += 1
        
        return ", ".join(args)
    
    def _generate_instruction(self, instr: MockInstruction,
                               tile_info: Dict[str, MockTileInfo]) -> List[str]:
        """Generate PTO ISA instruction code."""
        lines = []
        op = instr.opcode
        dst = instr.dst
        operands = instr.operands
        
        # Control flow
        if op == "FOR":
            iv = dst
            lb = operands[0]
            ub = operands[1]
            step = operands[2] if len(operands) > 2 else "1"
            lines.append(f"for (int {iv} = {lb}; {iv} < {ub}; {iv} += {step}) {{")
        elif op == "ENDFOR":
            lines.append("}")
        elif op == "IF":
            cond = operands[0] if operands else "true"
            lines.append(f"if ({cond}) {{")
        elif op == "ELSE":
            lines.append("} else {")
        elif op == "ENDIF":
            lines.append("}")
        elif op == "RETURN":
            lines.append("return;")
            
        # Scalar operations
        elif op == "SLI":
            lines.append(f"int {dst} = {operands[0]};")
        elif op in ("SADD", "SSUB", "SMUL", "SDIV"):
            op_map = {"SADD": "+", "SSUB": "-", "SMUL": "*", "SDIV": "/"}
            lines.append(f"int {dst} = {operands[0]} {op_map[op]} {operands[1]};")
        elif op == "SMOV":
            lines.append(f"int {dst} = {operands[0]};")
            
        # Memory operations
        elif op == "TLOAD":
            src_mem = operands[0]
            # For cube functions, load into _mat tile first
            is_cube = getattr(self, '_current_is_cube', False)
            dst_lower = dst.lower()
            if is_cube and (dst_lower in ('a', 'b') or 'left' in dst_lower or 'right' in dst_lower):
                # Load to Mat tile, then move to Left/Right
                lines.append(f"// TLOAD: {dst}_mat = load({src_mem})")
                lines.append(f"TLOAD({dst}_mat, g_{src_mem});")
                lines.append(f"// TMOV: {dst}_mat -> {dst} (Mat -> Left/Right)")
                lines.append(f"TMOV({dst}, {dst}_mat);")
            else:
                lines.append(f"// TLOAD: {dst} = load({src_mem})")
                lines.append(f"TLOAD({dst}, g_{src_mem});")
        elif op == "TSTORE":
            src = operands[0]
            # TSTORE supports Vec/Mat/Acc tiles directly to global memory
            lines.append(f"// TSTORE: store({src}) -> {dst}")
            lines.append(f"TSTORE(g_{dst}, {src});")
        elif op == "TCOPY":
            lines.append(f"// TCOPY: {dst} = {operands[0]}")
            lines.append(f"TCOPY({dst}, {operands[0]});")
            
        # Matrix multiplication (Cube)
        elif op == "TMATMUL":
            src0, src1 = operands[0], operands[1]
            lines.append(f"// TMATMUL: {dst} = {src0} @ {src1}")
            lines.append(f"TMATMUL({dst}, {src0}, {src1});")
        elif op == "TMATMUL_ACC":
            c_in, src0, src1 = operands[0], operands[1], operands[2]
            lines.append(f"// TMATMUL_ACC: {dst} = {c_in} + {src0} @ {src1}")
            lines.append(f"TMATMUL_ACC({dst}, {c_in}, {src0}, {src1});")
            
        # Binary operations (Vector)
        elif op in ("TADD", "TSUB", "TMUL", "TDIV", "TMAX", "TMIN"):
            src0, src1 = operands[0], operands[1]
            lines.append(f"// {op}: {dst} = {src0} op {src1}")
            lines.append(f"{op}({dst}, {src0}, {src1});")
            
        # Unary operations
        elif op in ("TABS", "TNEG", "TRECIP", "TEXP", "TLOG", "TSQRT", "TRSQRT",
                    "TRELU", "TSIGMOID", "TTANH", "TGELU", "TSILU"):
            src = operands[0]
            lines.append(f"// {op}: {dst} = op({src})")
            lines.append(f"{op}({dst}, {src});")
            
        # Scalar-tile operations
        elif op in ("TADDS", "TSUBS", "TMULS", "TDIVS", "TMAXS", "TMINS"):
            src0, scalar = operands[0], operands[1]
            lines.append(f"// {op}: {dst} = {src0} op {scalar}")
            lines.append(f"{op}({dst}, {src0}, {scalar});")
        elif op == "TEXPANDS":
            scalar = operands[0]
            lines.append(f"// TEXPANDS: {dst} = broadcast({scalar})")
            lines.append(f"TEXPANDS({dst}, {scalar});")
            
        # Reduction operations
        elif op in ("TROWSUM", "TROWMAX", "TROWMIN", "TCOLSUM", "TCOLMAX", "TCOLMIN"):
            src = operands[0]
            lines.append(f"// {op}: {dst} = reduce({src})")
            lines.append(f"{op}({dst}, {src});")
            
        # Row-wise broadcast operations
        elif op in ("TROWEXPANDSUB", "TROWEXPANDDIV", "TROWEXPANDMUL", "TROWEXPANDADD"):
            src0, src1 = operands[0], operands[1]
            lines.append(f"// {op}: {dst} = {src0} broadcast_op {src1}")
            lines.append(f"{op}({dst}, {src0}, {src1});")
            
        # Function call
        elif op == "CALL":
            callee = dst
            args = ", ".join(str(a) for a in operands) if operands else ""
            lines.append(f"{callee}({args});")
            
        else:
            lines.append(f"// Unknown op: {op}")
        
        return lines
    
    def _get_cpp_type(self, dtype: str) -> str:
        """Get C++ type for dtype string."""
        type_map = {
            "float": "float",
            "f32": "float",
            "half": "half",
            "f16": "half",
            "int32": "int32_t",
            "i32": "int32_t",
            "int64": "int64_t",
            "i64": "int64_t",
        }
        return type_map.get(dtype.lower(), "float")


# =============================================================================
# Code Generator Class
# =============================================================================

class AscendA2A3SimCodeGenerator:
    """
    Code generator for Ascend A2/A3 (both simulator and real hardware).
    
    Generates:
    - PTO ISA API calls for InCore functions (using pto::Tile, TLOAD, etc.)
    - Orchestration code with task submission
    - Integration with runtime (simulator or hardware)
    
    The generated code is identical for both targets, only the runtime
    headers/implementation differ.
    """
    
    def __init__(self, enable_fusion: bool = True, analyze_buffers: bool = True,
                 module: Optional[PTOModule] = None, target_mode: str = "sim"):
        """
        Initialize the code generator.
        
        Args:
            enable_fusion: Enable instruction fusion optimization
            analyze_buffers: Analyze buffer usage
            module: PTO module containing all functions
            target_mode: "sim" for simulator, "hardware" for real A2A3 hardware
        """
        self.enable_fusion = enable_fusion
        self.analyze_buffers = analyze_buffers
        self.module = module
        self.target_mode = target_mode
        self.incore_gen = PTOISAIncoreGenerator(module)
    
    def generate(self, program: PTOProgram) -> str:
        """Generate code for a program."""
        tile_info, mock_instructions = convert_program_to_mock_instructions(program)
        
        lines = []
        
        # Check if this is an orchestration function (not InCore)
        is_orchestration = not getattr(program, 'is_in_core', True)
        
        if is_orchestration:
            # Full code with main() for orchestration functions
            lines.append(generate_sim_header(self.target_mode))
            lines.append(generate_incore_function_registry())
            lines.append("")
            lines.append(self._generate_orchestration(program, mock_instructions, tile_info))
            
            # Generate main for standalone execution
            params = self._extract_params(program)
            lines.append(generate_sim_main(program.name, params))
        else:
            # For InCore functions, generate actual Ascend instructions
            lines.append(self.incore_gen.generate(program))
        
        return "\n".join(lines)
    
    def _extract_params(self, program: PTOProgram) -> List[Tuple[str, str]]:
        """Extract function parameters."""
        params = []
        
        # Memory references become pointers
        for name, memref_type in program.memref_declarations.items():
            c_type = ARM64_TYPE_MAP.get(memref_type.element_type.value, "float")
            params.append((f"{c_type}*", name))
        
        # Scalars (except internally initialized ones)
        for name, scalar_type in program.scalar_declarations.items():
            if scalar_type in (ElementType.U1, ElementType.INDEX):
                continue
            c_type = ARM64_TYPE_MAP.get(scalar_type.value, "int32_t")
            params.append((c_type, name))
        
        return params
    
    def _generate_orchestration(self, program: PTOProgram, 
                                 mock_instructions: List[MockInstruction],
                                 tile_info: Dict[str, MockTileInfo]) -> str:
        """Generate orchestration function code."""
        lines = []
        
        # Extract parameters
        params = self._extract_params(program)
        
        lines.append(f"// =============================================================================")
        lines.append(f"// Orchestration Function: {program.name}")
        lines.append(f"// Generates task graph for Ascend A2/A3 cycle-accurate simulation")
        lines.append(f"// =============================================================================")
        lines.append(f"//")
        lines.append(f"// Parameters passed via void** array:")
        for i, (c_type, name) in enumerate(params):
            lines.append(f"//   [{i}] {name} ({c_type})")
        lines.append(f"// =============================================================================")
        lines.append("")
        
        # Function signature - standard runtime interface with void** params
        lines.append(f"void {program.name}(PTORuntime* rt, void* user_data) {{")
        lines.append(f"    // Unpack parameters from void** array")
        lines.append(f"    void** params = (void**)user_data;")
        lines.append(f"    (void)params;  // Suppress unused warning if no params")
        lines.append("")
        
        # Extract each parameter from the array
        for i, (c_type, name) in enumerate(params):
            if '*' in c_type:
                # Pointer type - cast directly
                lines.append(f"    {c_type} {name} = ({c_type})params[{i}];")
            else:
                # Scalar type - dereference
                lines.append(f"    {c_type} {name} = *({c_type}*)params[{i}];")
        lines.append("")
        
        # Task counter
        lines.append("    int32_t _task_id = 0;")
        lines.append("")
        
        # Generate code for each instruction
        indent = "    "
        task_counter = 0
        
        for instr in mock_instructions:
            opcode = instr.opcode
            
            if opcode == "TLOAD" or opcode == "TSTORE":
                # Memory ops - just track dependencies
                pass
            
            elif opcode == "CALL":
                # Generate task submission
                func_name = instr.dst
                
                # Look up is_cube from the callee function in the module
                is_cube = False
                if self.module and func_name in self.module.functions:
                    callee_prog = self.module.functions[func_name]
                    is_cube = getattr(callee_prog, 'is_cube', False)
                
                # Fallback: check if operation name suggests cube (matmul, gemm)
                if not is_cube:
                    is_cube = (is_cube_op(func_name.upper()) or 
                               "matmul" in func_name.lower() or 
                               "gemm" in func_name.lower())
                
                cycle_cost = get_cycle_cost(func_name.upper()) if func_name.upper() in ASCEND_A2A3_CYCLE_COSTS else 10
                
                lines.append(f"{indent}// Task: {func_name} ({'Cube' if is_cube else 'Vector'} Core)")
                lines.append(f"{indent}{{")
                lines.append(f"{indent}    int32_t t = pto_task_alloc(rt, \"{func_name}\", NULL, 0, 0, {'true' if is_cube else 'false'});")
                
                # Analyze callee function to determine input/output memrefs
                callee_inputs = set()
                callee_outputs = set()
                
                if self.module and func_name in self.module.functions:
                    callee_prog = self.module.functions[func_name]
                    # Analyze instructions to find LOADs (inputs) and STOREs (outputs)
                    for callee_instr in callee_prog.instructions:
                        opcode = getattr(callee_instr, 'opcode', '')
                        if opcode == 'TLOAD':
                            # TLOAD loads from src_mem → it's an input
                            src_mem = getattr(callee_instr, 'src_mem', None)
                            if src_mem:
                                callee_inputs.add(src_mem.name if hasattr(src_mem, 'name') else str(src_mem))
                        elif opcode == 'TSTORE':
                            # TSTORE stores to dst_mem → it's an output
                            dst_mem = getattr(callee_instr, 'dst_mem', None)
                            if dst_mem:
                                callee_outputs.add(dst_mem.name if hasattr(dst_mem, 'name') else str(dst_mem))
                
                # Add inputs/outputs from args
                if isinstance(instr.operands, dict):
                    for arg_name, arg_info in instr.operands.items():
                        if isinstance(arg_info, tuple) and len(arg_info) >= 3:
                            tensor, row_idx, col_idx = arg_info[0], arg_info[1], arg_info[2]
                            rows = arg_info[3] if len(arg_info) > 3 else 32
                            cols = arg_info[4] if len(arg_info) > 4 else 128
                            
                            # Determine if this is input, output, or both based on callee analysis
                            is_input = arg_name in callee_inputs or (not callee_inputs and not callee_outputs)
                            is_output = arg_name in callee_outputs
                            
                            # Fallback heuristics if analysis didn't find anything
                            if not callee_inputs and not callee_outputs:
                                is_output = 'out' in arg_name.lower() or 'dst' in arg_name.lower()
                                is_input = not is_output
                            
                            # Add both input and output if memref is read and written
                            if is_input:
                                lines.append(f"{indent}    pto_task_add_input(rt, t, {tensor}, {row_idx}, {col_idx}, {rows}, {cols});")
                            if is_output:
                                lines.append(f"{indent}    pto_task_add_output(rt, t, {tensor}, {row_idx}, {col_idx}, {rows}, {cols});")
                
                # Set cycle cost (can use core simulator or heuristic)
                lines.append(f"{indent}    // Cycle cost: {cycle_cost} (heuristic), use core sim for accurate timing")
                lines.append(f"{indent}    pto_task_submit(rt, t);")
                lines.append(f"{indent}}}")
                lines.append("")
                task_counter += 1
            
            elif opcode == "FOR":
                iv = instr.dst
                lb = instr.operands[0] if instr.operands else "0"
                ub = instr.operands[1] if len(instr.operands) > 1 else "1"
                step = instr.operands[2] if len(instr.operands) > 2 else "1"
                lines.append(f"{indent}for (int {iv} = {lb}; {iv} < {ub}; {iv} += {step}) {{")
                indent += "    "
            
            elif opcode == "ENDFOR":
                indent = indent[:-4]
                lines.append(f"{indent}}}")
            
            elif opcode == "IF":
                cond = instr.operands[0] if instr.operands else "true"
                lines.append(f"{indent}if ({cond}) {{")
                indent += "    "
            
            elif opcode == "ELSE":
                indent = indent[:-4]
                lines.append(f"{indent}}} else {{")
                indent += "    "
            
            elif opcode == "ENDIF":
                indent = indent[:-4]
                lines.append(f"{indent}}}")
            
            elif opcode == "SLI":
                # Scalar load immediate
                dst = instr.dst
                val = instr.operands[0] if instr.operands else "0"
                lines.append(f"{indent}// SLI: {dst} = {val}")
        
        lines.append("}")
        
        return "\n".join(lines)


# =============================================================================
# Convenience Functions
# =============================================================================

def generate_ascend_a2a3_sim_code(program: PTOProgram, 
                                   enable_fusion: bool = True,
                                   module: Optional[PTOModule] = None) -> str:
    """Generate Ascend A2/A3 simulation code."""
    gen = AscendA2A3SimCodeGenerator(
        enable_fusion=enable_fusion,
        module=module
    )
    return gen.generate(program)


# =============================================================================
# Export
# =============================================================================

__all__ = [
    'AscendA2A3SimCodeGenerator',
    'AscendA2A3SimIncoreGenerator',
    'generate_ascend_a2a3_sim_code',
    'ASCEND_A2A3_CYCLE_COSTS',
    'get_cycle_cost',
    'is_cube_op',
    'CUBE_OPS',
    'VECTOR_OPS',
]
